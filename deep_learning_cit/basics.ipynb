{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8103, 0.2412, 0.6995],\n",
      "        [0.9520, 0.8044, 0.6235],\n",
      "        [0.8022, 0.4941, 0.2160],\n",
      "        [0.5460, 0.2715, 0.9185],\n",
      "        [0.4589, 0.1977, 0.5572]])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n"
     ]
    }
   ],
   "source": [
    "# initializing two arrays\n",
    "a = np.array(2)\n",
    "b = np.array(1)\n",
    "print(a,b)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "-1\n",
      "2\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "print(a+b)\n",
    "\n",
    "# subtraction\n",
    "print(b-a)\n",
    "\n",
    "# multiplication\n",
    "print(a*b)\n",
    "\n",
    "# division\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Let’s now see how we can do the same using PyTorch on tensors. So, first, let’s initialize two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# initializing two tensors\n",
    "a = torch.tensor(2)\n",
    "b = torch.tensor(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the operations which we saw in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n",
      "tensor(-1)\n",
      "tensor(2)\n",
      "tensor(2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\aten\\src\\ATen\\native\\BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "print(a+b)\n",
    "\n",
    "# subtraction\n",
    "print(b-a)\n",
    "\n",
    "# multiplication\n",
    "print(a*b)\n",
    "\n",
    "# division\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrix Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "# matrix of zeros\n",
    "a = np.zeros((3,3))\n",
    "print(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Matrix Initialization with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# matrix of zeros\n",
    "a = torch.zeros((3,3))\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random numbers initialization- Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02637477,  0.2603217 , -0.39514554],\n",
       "       [-0.20430091, -1.27163265, -2.59687863],\n",
       "       [ 0.28968091, -0.87330464,  0.39407266]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the random seed for numpy\n",
    "np.random.seed(45)\n",
    "\n",
    "#matrix of random numbers\n",
    "a = np.random.randn(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345],\n",
       "        [ 0.2303, -1.1229, -0.1863],\n",
       "        [ 2.2082, -0.6380,  0.4617]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting the random seed for pytorch\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# matrix of random numbers\n",
    "a = torch.randn(3,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### matrix operations - numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0392742  -0.60168199  0.18195878]\n",
      " [ 1.76499213 -2.14743362 -1.95905479]\n",
      " [ 1.01692529 -0.24539639 -0.15522705]] \n",
      "\n",
      "[[-0.04584589  0.32515339  1.11341829]\n",
      " [ 1.28106758  1.67912687  1.49078088]\n",
      " [ 2.14150034  1.78026585 -0.78372172]] \n",
      "\n",
      "[[-0.12814468 -0.62164688  0.21069439]\n",
      " [ 0.90133115 -0.02065676 -0.3790019 ]\n",
      " [ 1.30648762 -1.7246546  -2.20677932]] \n",
      "\n",
      "[[ 0.9155008   0.29835784 -1.39069607]\n",
      " [ 6.29449313  0.12238321  0.13573803]\n",
      " [-2.80855031 -0.75771243 -1.49396459]]\n"
     ]
    }
   ],
   "source": [
    "# setting the random seed for numpy and initializing two matrices\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(3,3)\n",
    "b = np.random.randn(3,3)\n",
    "\n",
    "\n",
    "# matrix addition\n",
    "print(np.add(a,b), '\\n')\n",
    "\n",
    "# matrix subtraction\n",
    "print(np.subtract(a,b), '\\n')\n",
    " \n",
    "# matrix multiplication\n",
    "print(np.dot(a,b), '\\n')\n",
    " \n",
    "# matrix multiplication\n",
    "print(np.divide(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### matrix operations - pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6040,  0.6637,  1.0438],\n",
      "        [ 1.3406, -2.8127, -1.1753],\n",
      "        [ 3.1662,  0.6841,  1.2788]]) \n",
      "\n",
      "tensor([[ 0.0693, -0.4061, -0.5749],\n",
      "        [-0.8800,  0.5669,  0.8026],\n",
      "        [ 1.2502, -1.9601, -0.3555]]) \n",
      "\n",
      "tensor([[ 0.4576,  0.2724,  0.3367],\n",
      "        [-1.3636,  1.7743,  1.1446],\n",
      "        [ 0.3243,  2.8696,  2.7954]]) \n",
      "\n",
      "tensor([[ 1.2594,  0.2408,  0.2897],\n",
      "        [ 0.2075,  0.6645,  0.1884],\n",
      "        [ 2.3051, -0.4826,  0.5649]])\n"
     ]
    }
   ],
   "source": [
    "# setting the random seed for pytorch and initializing two tensors\n",
    "torch.manual_seed(42)\n",
    "a = torch.randn(3,3)\n",
    "b = torch.randn(3,3)\n",
    "# matrix addition\n",
    "print(torch.add(a,b), '\\n')\n",
    "\n",
    "# matrix subtraction\n",
    "print(torch.sub(a,b), '\\n')\n",
    "\n",
    "# matrix multiplication\n",
    "print(torch.mm(a,b), '\\n')\n",
    "\n",
    "# matrix division\n",
    "print(torch.div(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix transpose is one technique which is also very useful while creating a neural network from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02637477  0.2603217  -0.39514554]\n",
      " [-0.20430091 -1.27163265 -2.59687863]\n",
      " [ 0.28968091 -0.87330464  0.39407266]] \n",
      "\n",
      "[[ 0.02637477 -0.20430091  0.28968091]\n",
      " [ 0.2603217  -1.27163265 -0.87330464]\n",
      " [-0.39514554 -2.59687863  0.39407266]]\n"
     ]
    }
   ],
   "source": [
    "# original matrix\n",
    "print(a, '\\n') \n",
    "\n",
    "# matrix transpose\n",
    "print(np.transpose(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02637477  0.2603217  -0.39514554]\n",
      " [-0.20430091 -1.27163265 -2.59687863]\n",
      " [ 0.28968091 -0.87330464  0.39407266]] \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "t(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-fb6da53e5857>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# matrix transpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: t(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# original matrix\n",
    "print(a, '\\n')\n",
    "\n",
    "# matrix transpose\n",
    "torch.t(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#converting numpy array to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# initializing a numpy array\n",
    "a = np.array([[1,2],[3,4]])\n",
    "print(a, '\\n')\n",
    "\n",
    "# converting the numpy array to tensor\n",
    "tensor = torch.from_numpy(a)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUTOGRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing a tensor\n",
    "a = torch.ones((2,2), requires_grad=True)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# performing operations on the tensor\n",
    "b = a + 5\n",
    "c = b.mean()\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b = a + 5\n",
    "\n",
    "c = mean(b) = Σ(a+5) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the derivative of c w.r.t. a will be ¼ and hence the gradient matrix will be 0.25. Let’s verify this using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.2500],\n",
      "        [0.2500, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "# back propagating\n",
    "c.backward() \n",
    "\n",
    "# computing gradients\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### OPTIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the optim module\n",
    "from torch import optim\n",
    "\n",
    "# adam\n",
    "## adam = optim.Adam(model.parameters(), lr=learning_rate)\n",
    " \n",
    "# sgd\n",
    "## SGD = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network from Scratch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]]) \n",
      "\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "#Input tensor\n",
    "X = torch.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "\n",
    "#Output\n",
    "y = torch.Tensor([[1],[1],[0]])\n",
    "\n",
    "print(X, '\\n')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will define the sigmoid function which will act as the activation function and the derivative of the sigmoid function which will help us in the backpropagation step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sigmoid Function\n",
    "def sigmoid (x):\n",
    "   return 1/(1 + torch.exp(-x))\n",
    "\n",
    "#Derivative of Sigmoid Function/\n",
    "def derivatives_sigmoid(x):\n",
    "   return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize the parameters for our model including the number of epochs, learning rate, weights, biases, etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable initialization\n",
    "\n",
    "epoch=7000 #Setting training iterations\n",
    "\n",
    "lr=0.1 #Setting learning rate\n",
    "\n",
    "inputlayer_neurons = X.shape[1] #number of features in data set\n",
    "\n",
    "hiddenlayer_neurons = 3 #number of hidden layer neurons\n",
    "\n",
    "output_neurons = 1 #number of neurons in output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight and bias initialization\n",
    "wh=torch.randn(inputlayer_neurons, hiddenlayer_neurons).type(torch.FloatTensor)\n",
    "bh=torch.randn(1, hiddenlayer_neurons).type(torch.FloatTensor)\n",
    "wout=torch.randn(hiddenlayer_neurons, output_neurons)\n",
    "bout=torch.randn(1, output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "   #Forward Propogation\n",
    "   hidden_layer_input1 = torch.mm(X, wh)\n",
    "   hidden_layer_input = hidden_layer_input1 + bh\n",
    "   hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "   \n",
    "   output_layer_input1 = torch.mm(hidden_layer_activations, wout)\n",
    "   output_layer_input = output_layer_input1 + bout\n",
    "   output = sigmoid(output_layer_input)\n",
    "\n",
    "   #Backpropagation\n",
    "   E = y-output\n",
    "   slope_output_layer = derivatives_sigmoid(output)\n",
    "   slope_hidden_layer = derivatives_sigmoid(hidden_layer_activations)\n",
    "   d_output = E * slope_output_layer\n",
    "   Error_at_hidden_layer = torch.mm(d_output, wout.t())\n",
    "   d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "\n",
    "   wout += torch.mm(hidden_layer_activations.t(), d_output) *lr\n",
    "   bout += d_output.sum() *lr\n",
    "   wh += torch.mm(X.t(), d_hiddenlayer) *lr\n",
    "   bh += d_output.sum() *lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In the forward propagation step, we are calculating the output and finally, in the backward propagation step, we are calculating the error. We will then update the weights and biases using this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual :\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]]) \n",
      "\n",
      "predicted :\n",
      " tensor([[0.9965],\n",
      "        [0.9963],\n",
      "        [0.0055]])\n"
     ]
    }
   ],
   "source": [
    "print('actual :\\n', y, '\\n')\n",
    "print('predicted :\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
